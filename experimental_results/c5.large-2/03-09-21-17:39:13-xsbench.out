--------------------------------------------------------------------------
[[17462,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: ip-172-31-3-141

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
================================================================================
                   __   __ ___________                 _                        
                   \ \ / //  ___| ___ \               | |                       
                    \ V / \ `--.| |_/ / ___ _ __   ___| |__                     
                    /   \  `--. \ ___ \/ _ \ '_ \ / __| '_ \                    
                   / /^\ \/\__/ / |_/ /  __/ | | | (__| | | |                   
                   \/   \/\____/\____/ \___|_| |_|\___|_| |_|                   

================================================================================
                    Developed at Argonne National Laboratory
                                   Version: 19
================================================================================
                                  INPUT SUMMARY
================================================================================
Simulation Method:            History Based
Grid Type:                    Nuclide Grid
Materials:                    12
H-M Benchmark Size:           large
Total Nuclides:               355
Gridpoints (per Nuclide):     11,303
Particle Histories:           500,000
XS Lookups per Particle:      34
Total XS Lookups:             34
MPI Ranks:                    2
OMP Threads per MPI Rank:     1
Mem Usage per MPI Rank (MB):  184
Binary File Mode:             Off
================================================================================
                         INITIALIZATION - DO NOT PROFILE
================================================================================
Intializing nuclide grids...
Intializing material data...
Intialization complete. Allocated 184 MB of data.

================================================================================
                                   SIMULATION
================================================================================
Beginning history based simulation...
[PI-INFO] Init time,0,0.694744
[PI-INFO] Init time,1,0.687867
[PI-INFO] Paramount Iteration,0,1,0.695844,0.001100
[PI-INFO] Paramount Iteration,1,1,0.688992,0.001125
[PI-INFO] Paramount Iteration,0,2,0.696645,0.000801
[PI-INFO] Paramount Iteration,1,2,0.689757,0.000765
[PI-INFO] Paramount Iteration,0,3,0.697234,0.000589
[PI-INFO] Paramount Iteration,1,3,0.690338,0.000581
[PI-INFO] Paramount Iteration,0,4,0.697909,0.000675
[PI-INFO] Paramount Iteration,1,4,0.690993,0.000655
[PI-INFO] Paramount Iteration,0,5,0.698343,0.000434
[PI-INFO] Paramount Iteration,1,5,0.691414,0.000421
[PI-INFO] Paramount Iteration,0,6,0.699013,0.000670
[PI-INFO] Paramount Iteration,1,6,0.692082,0.000668
[PI-INFO] Paramount Iteration,0,7,0.699622,0.000609
[PI-INFO] Paramount Iteration,1,7,0.692678,0.000596
[PI-INFO] Paramount Iteration,0,8,0.700190,0.000568
[PI-INFO] Paramount Iteration,1,8,0.693253,0.000575
[PI-INFO] Paramount Iteration,0,9,0.700773,0.000583
[PI-INFO] Paramount Iteration,1,9,0.693833,0.000580
[PI-INFO] Paramount Iteration,0,10,0.701521,0.000748
[PI-INFO] Paramount Iteration,1,10,0.694579,0.000746
[PI-INFO] Paramount Iteration,0,11,0.702236,0.000715
[PI-INFO] Paramount Iteration,1,11,0.695269,0.000690
[PI-INFO] Paramount Iteration,0,12,0.702783,0.000547
[PI-INFO] Paramount Iteration,1,12,0.695805,0.000536
[PI-INFO] Paramount Iteration,0,13,0.703248,0.000465
[PI-INFO] Paramount Iteration,1,13,0.696265,0.000460
[PI-INFO] Paramount Iteration,0,14,0.703942,0.000694
[PI-INFO] Paramount Iteration,1,14,0.696967,0.000702
[PI-INFO] Paramount Iteration,0,15,0.704403,0.000461
[PI-INFO] PI avg,0,0.000644,15
[PI-INFO] Beta,0,0.001135
[PI-INFO] Total time,0.704413
[PI-INFO] Paramount Iteration,1,15,0.697423,0.000456
[PI-INFO] PI avg,1,0.000637,15
[PI-INFO] Beta,1,0.001272
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 0 on
node ip-172-31-3-141 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).

You can avoid this message by specifying -quiet on the mpirun command line.
--------------------------------------------------------------------------
[ip-172-31-3-141:16601] 1 more process has sent help message help-mpi-btl-base.txt / btl:no-nics
[ip-172-31-3-141:16601] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
