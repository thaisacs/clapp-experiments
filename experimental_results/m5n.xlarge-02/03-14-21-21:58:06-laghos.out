Warning: Permanently added '172.31.15.183' (ECDSA) to the list of known hosts.
--------------------------------------------------------------------------
[[43474,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: ip-172-31-13-196

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------

       __                __                 
      / /   ____  ____  / /_  ____  _____   
     / /   / __ `/ __ `/ __ \/ __ \/ ___/ 
    / /___/ /_/ / /_/ / / / / /_/ (__  )    
   /_____/\__,_/\__, /_/ /_/\____/____/  
               /____/                       

Options used:
   --dimension 3
   --mesh data/rectangle01_quad.mesh
   --refine-serial 2
   --refine-parallel 0
   --cartesian-partitioning ''
   --problem 3
   --order-kinematic 2
   --order-thermo 1
   --order-intrule -1
   --ode-solver 4
   --t-final 5
   --cfl 0.5
   --cg-tol 1e-08
   --ftz-tol 0
   --cg-max-steps 300
   --max-steps -1
   --partial-assembly
   --no-impose-viscosity
   --no-visualization
   --visualization-steps 5
   --no-visit
   --no-print
   --outputfilename results/Laghos
   --partition 0
   --device cpu
   --no-checks
   --no-mem
   --no-fom
   --no-gpu-aware-mpi
   --dev 0
Device configuration: cpu
Memory configuration: host-std
Number of zones in the serial mesh: 336
Non-Cartesian partitioning through METIS will be used.
Zones min/max: 168 168
Number of kinematic (position, velocity) dofs: 2850
Number of specific internal energy dofs: 1344
[PI-INFO] Init time,0,0.019376
[PI-INFO] Init time,1,0.019378
Repeating step 1
[PI-INFO] Paramount Iteration,0,1,0.047628,0.028253
[PI-INFO] Paramount Iteration,1,1,0.047617,0.028239
Repeating step 1
[PI-INFO] Paramount Iteration,0,2,0.075974,0.028346
[PI-INFO] Paramount Iteration,1,2,0.075966,0.028349
Repeating step 1
[PI-INFO] Paramount Iteration,0,3,0.104390,0.028416
[PI-INFO] Paramount Iteration,1,3,0.104379,0.028413
Repeating step 1
[PI-INFO] Paramount Iteration,0,4,0.132534,0.028144
[PI-INFO] Paramount Iteration,1,4,0.132520,0.028141
[PI-INFO] Paramount Iteration,0,5,0.160684,0.028150
[PI-INFO] Paramount Iteration,1,5,0.160692,0.028172
Repeating step 2
[PI-INFO] Paramount Iteration,0,6,0.189527,0.028843
[PI-INFO] Paramount Iteration,1,6,0.189493,0.028801
[PI-INFO] Paramount Iteration,0,7,0.218918,0.029391
[PI-INFO] Paramount Iteration,1,7,0.218926,0.029433
Repeating step 3
[PI-INFO] Paramount Iteration,0,8,0.247392,0.028474
[PI-INFO] Paramount Iteration,1,8,0.247376,0.028450
[PI-INFO] Paramount Iteration,0,9,0.276403,0.029011
[PI-INFO] Paramount Iteration,1,9,0.276389,0.029013
[PI-INFO] Paramount Iteration,0,10,0.304725,0.028322
[PI-INFO] Paramount Iteration,1,10,0.304736,0.028347
step     5,	t = 0.0476,	dt = 0.008554,	|e| = 4.7764852179e+01
[PI-INFO] Paramount Iteration,0,11,0.333777,0.029052
[PI-INFO] Paramount Iteration,1,11,0.333779,0.029043
Repeating step 6
[PI-INFO] Paramount Iteration,0,12,0.362141,0.028364
[PI-INFO] Paramount Iteration,1,12,0.362129,0.028350
[PI-INFO] Paramount Iteration,0,13,0.391192,0.029051
[PI-INFO] Paramount Iteration,1,13,0.391199,0.029070
[PI-INFO] Paramount Iteration,0,14,0.420208,0.029016
[PI-INFO] Paramount Iteration,1,14,0.420207,0.029008
[PI-INFO] Paramount Iteration,0,15,0.448681,0.028473
[PI-INFO] PI avg,0,0.028620,15
[PI-INFO] Beta,0,0.000044
[PI-INFO] Total time,0.448699
[PI-INFO] Paramount Iteration,1,15,0.448676,0.028469
[PI-INFO] PI avg,1,0.028620,15
[PI-INFO] Beta,1,0.000031
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 0 on
node ip-172-31-13-196 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).

You can avoid this message by specifying -quiet on the mpirun command line.
--------------------------------------------------------------------------
[ip-172-31-13-196:16070] 1 more process has sent help message help-mpi-btl-base.txt / btl:no-nics
[ip-172-31-13-196:16070] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Command exited with non-zero status 1
	Command being timed: "mpirun --hostfile /home/ubuntu/PI-Bench/ECP-Proxy-Apps/hostfile -n 2 ./laghos -p 3 -m data/rectangle01_quad.mesh -rs 2 -tf 5.0 -pa"
	User time (seconds): 0.31
	System time (seconds): 0.19
	Percent of CPU this job got: 15%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:03.32
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 19840
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 11
	Minor (reclaiming a frame) page faults: 5274
	Voluntary context switches: 858
	Involuntary context switches: 26
	Swaps: 0
	File system inputs: 1440
	File system outputs: 16424
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 1
